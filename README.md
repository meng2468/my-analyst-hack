# Voice Agent with OpenAI & ElevenLabs Integration

A full-stack voice agent application that combines real-time speech recognition with AI-powered responses using OpenAI and high-quality text-to-speech using ElevenLabs API. The application features a modern React frontend with Web Speech API and a FastAPI backend for intelligent conversation and premium voice synthesis.

## ğŸ¯ Features

### Frontend (Next.js + React)
- ğŸ¤ **Real-time Speech Recognition** - Uses Web Speech API for instant transcription
- ğŸ¤– **AI-Powered Responses** - OpenAI integration for intelligent conversation
- ğŸµ **High-Quality TTS** - ElevenLabs integration for premium voice synthesis
- ğŸ”„ **Fallback System** - Automatic fallback to simple responses if backend unavailable
- ğŸ¨ **Modern UI** - Beautiful, responsive interface with real-time feedback
- ğŸ›ï¸ **Voice Selection** - Choose from multiple ElevenLabs voices
- ğŸ’¬ **Conversation History** - Chat-like interface with timestamps
- ğŸ“± **Mobile Responsive** - Works on desktop and mobile devices

### Backend (FastAPI)
- ğŸš€ **AI Chat Processing** - OpenAI GPT-3.5-turbo for intelligent responses
- ğŸµ **Streaming Audio** - Real-time audio streaming from text
- ğŸµ **Multiple Voices** - Access to all ElevenLabs voices
- ğŸ“Š **Usage Monitoring** - Track API usage and limits
- ğŸ”§ **RESTful API** - Clean, documented endpoints
- ğŸŒ **CORS Support** - Ready for frontend integration
- ğŸ“š **Auto-generated Docs** - Swagger UI and ReDoc

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    HTTP/WebSocket    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend      â”‚ â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚    Backend      â”‚
â”‚   (Next.js)     â”‚                      â”‚   (FastAPI)     â”‚
â”‚                 â”‚                      â”‚                 â”‚
â”‚ â€¢ Speech Rec.   â”‚                      â”‚ â€¢ OpenAI Chat   â”‚
â”‚ â€¢ Voice UI      â”‚                      â”‚ â€¢ ElevenLabs    â”‚
â”‚ â€¢ Fallback TTS  â”‚                      â”‚ â€¢ TTS Streaming â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                                        â”‚
         â”‚                                        â”‚
         â–¼                                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Web Speech API â”‚                      â”‚  OpenAI API     â”‚
â”‚                 â”‚                      â”‚                 â”‚
â”‚ â€¢ Speech Rec.   â”‚                      â”‚ â€¢ GPT-3.5-turbo â”‚
â”‚ â€¢ Browser TTS   â”‚                      â”‚ â€¢ Chat Complet. â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                â”‚
                                                â–¼
                                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                       â”‚  ElevenLabs API â”‚
                                       â”‚                 â”‚
                                       â”‚ â€¢ Text-to-Speechâ”‚
                                       â”‚ â€¢ Voice Models  â”‚
                                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### Prerequisites
- **Python 3.8+** with pip
- **Node.js 16+** with npm
- **OpenAI API Key** (get one at [platform.openai.com](https://platform.openai.com/api-keys))
- **ElevenLabs API Key** (free account at [elevenlabs.io](https://elevenlabs.io))

### 1. Clone and Setup

```bash
git clone <repository-url>
cd my-analyst-hack
```

### 2. Configure API Keys

```bash
cd backend
cp env.example .env
```

Edit `.env` and add your API keys:
```env
# OpenAI API Configuration
OPENAI_API_KEY=your_openai_api_key_here

# ElevenLabs API Configuration
ELEVENLABS_API_KEY=your_elevenlabs_api_key_here

# Server Configuration
HOST=0.0.0.0
PORT=8000
```

### 3. Start the Application

#### Option A: Use the startup script (Recommended)
```bash
./start.sh
```

#### Option B: Manual startup

**Backend:**
```bash
cd backend
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt
python main.py
```

**Frontend (in new terminal):**
```bash
cd telli-hack
npm install
npm run dev
```

### 4. Access the Application

- **Frontend**: http://localhost:3000
- **Backend API**: http://localhost:8000
- **API Documentation**: http://localhost:8000/docs

## ğŸ® How to Use

1. **Start Listening**: Click the "Start Listening" button
2. **Speak**: Say something clearly into your microphone
3. **Get AI Response**: The agent will transcribe your speech, process it with OpenAI, and respond with high-quality audio
4. **Choose Voice**: Select different voices from the dropdown menu
5. **View History**: See your conversation history in the chat interface

### Example Conversations
- Ask questions: "What's the weather like?", "Tell me a joke", "How do I make coffee?"
- Get information: "What time is it?", "What's today's date?", "Explain quantum physics"
- Have a chat: "Hello", "How are you?", "Tell me about yourself"

## ğŸ”§ API Endpoints

### Health & Status
- `GET /` - Root endpoint
- `GET /health` - Health check with OpenAI and ElevenLabs status

### AI Chat
- `POST /chat` - Process user message with OpenAI and return text + audio

### Text-to-Speech
- `POST /tts/stream` - Stream audio response
- `POST /tts` - Get complete audio file

### Voice Management
- `GET /voices` - List available voices
- `GET /usage` - Get API usage statistics

## ğŸ§ª Testing

### Test the Backend
```bash
cd backend
python test_api.py
```

### Test the Frontend
1. Open http://localhost:3000
2. Allow microphone permissions
3. Try asking questions or having a conversation

## ğŸ“ Project Structure

```
my-analyst-hack/
â”œâ”€â”€ backend/                 # FastAPI backend
â”‚   â”œâ”€â”€ main.py             # Main FastAPI application with OpenAI integration
â”‚   â”œâ”€â”€ requirements.txt    # Python dependencies
â”‚   â”œâ”€â”€ test_api.py         # API testing script
â”‚   â”œâ”€â”€ env.example         # Environment variables template
â”‚   â””â”€â”€ README.md           # Backend documentation
â”œâ”€â”€ telli-hack/             # Next.js frontend
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ _components/
â”‚   â”‚   â”‚   â””â”€â”€ VoiceUI.tsx # Main voice interface with OpenAI chat
â”‚   â”‚   â”œâ”€â”€ types/
â”‚   â”‚   â”‚   â””â”€â”€ speech.d.ts # Web Speech API types
â”‚   â”‚   â”œâ”€â”€ page.tsx        # Main page
â”‚   â”‚   â””â”€â”€ layout.tsx      # App layout
â”‚   â”œâ”€â”€ package.json        # Node.js dependencies
â”‚   â””â”€â”€ tsconfig.json       # TypeScript config
â”œâ”€â”€ start.sh                # Startup script
â””â”€â”€ README.md               # This file
```

## ğŸ”§ Configuration

### Environment Variables

**Backend (.env):**
```env
# OpenAI API Configuration
OPENAI_API_KEY=your_openai_api_key_here

# ElevenLabs API Configuration
ELEVENLABS_API_KEY=your_elevenlabs_api_key_here

# Server Configuration
HOST=0.0.0.0
PORT=8000
```

### OpenAI Configuration

The backend uses GPT-3.5-turbo with the following settings:
```python
model="gpt-3.5-turbo"
max_tokens=150
temperature=0.7
```

### Voice Settings

You can customize voice parameters:
```json
{
  "text": "Hello world!",
  "voice_id": "21m00Tcm4TlvDq8ikWAM",
  "voice_settings": {
    "stability": 0.5,
    "similarity_boost": 0.75,
    "style": 0.0,
    "use_speaker_boost": true
  }
}
```

## ğŸ› Troubleshooting

### Common Issues

1. **"Speech recognition not supported"**
   - Use Chrome, Firefox, or Safari
   - Ensure HTTPS or localhost

2. **"OpenAI API key not configured"**
   - Check your `.env` file in the backend directory
   - Verify your API key is valid at [platform.openai.com](https://platform.openai.com/api-keys)

3. **"ElevenLabs API key not configured"**
   - Check your `.env` file in the backend directory
   - Verify your API key is valid

4. **"CORS errors"**
   - Backend is configured for `localhost:3000`
   - Check that both servers are running

5. **"Audio not playing"**
   - Check browser audio permissions
   - Try refreshing the page

6. **"Backend connection failed"**
   - Ensure backend is running on port 8000
   - Check firewall settings

### Debug Mode

**Backend:**
```bash
cd backend
uvicorn main:app --reload --log-level debug
```

**Frontend:**
```bash
cd telli-hack
npm run dev
# Check browser console for errors
```

## ğŸš€ Deployment

### Backend Deployment
- Deploy to platforms like Heroku, Railway, or DigitalOcean
- Set environment variables in your deployment platform
- Ensure CORS origins are updated for production

### Frontend Deployment
- Deploy to Vercel, Netlify, or similar platforms
- Update backend URL in production environment
- Configure environment variables

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests if applicable
5. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License.

## ğŸ™ Acknowledgments

- [OpenAI](https://openai.com) for AI-powered conversation capabilities
- [ElevenLabs](https://elevenlabs.io) for high-quality text-to-speech
- [Web Speech API](https://developer.mozilla.org/en-US/docs/Web/API/Web_Speech_API) for speech recognition
- [FastAPI](https://fastapi.tiangolo.com/) for the backend framework
- [Next.js](https://nextjs.org/) for the frontend framework

## ğŸ“ Support

If you encounter any issues:
1. Check the troubleshooting section
2. Review the API documentation at http://localhost:8000/docs
3. Check the browser console for frontend errors
4. Review the backend logs for server errors 